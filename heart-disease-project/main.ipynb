{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict heart disease using Machine Learning\n",
    "\n",
    "this notebook looks into using various Python-based machine learning and data science libraries to build a machine learning model capable of predicting whether or not someone has heart disease.\n",
    "\n",
    "We are going to take the following steps:\n",
    "\n",
    "1. Problem definition\n",
    "2. Data\n",
    "3. Evaluation\n",
    "4. Features\n",
    "5. Modeling\n",
    "6. Experimentation\n",
    "\n",
    "## 1. Problem definition\n",
    "\n",
    "In a statement,\n",
    "\n",
    "> Given clinical parameters about a patient, can we predict whether or not they have heart disease?\n",
    "\n",
    "## 2. Data\n",
    "\n",
    "The original data came from the Cleavland data from the UCI Machine Learning Repository. [click here](https://archive.ics.uci.edu/ml/datasets/heart+Disease)\n",
    "\n",
    "## 3. Evaluation\n",
    "\n",
    "> if we can reach an accuracy greater than 0.9, we'll pursue the project.\n",
    "\n",
    "## 4. Features\n",
    "\n",
    "What features that we will use ?\n",
    "This is where we different information about our dataset\n",
    "\n",
    "**Create a data dictionary**\n",
    "\n",
    "1. age - age in years\n",
    "2. sex - (1 = male; 0 = female)\n",
    "3. cp - chest pain type\n",
    "   - 0: Typical angina: chest pain related decrease blood supply to the heart\n",
    "   - 1: Atypical angina: chest pain not related to heart\n",
    "   - 2: Non-anginal pain: typically esophageal spasms (non heart related)\n",
    "   - 3: Asymptomatic: chest pain not showing signs of disease\n",
    "4. trestbps - resting blood pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern\n",
    "5. chol - serum cholestoral in mg/dl\n",
    "   - serum = LDL + HDL + .2 \\* triglycerides\n",
    "   - above 200 is cause for concern\n",
    "6. fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "   - '>126' mg/dL signals diabetes\n",
    "7. restecg - resting electrocardiographic results\n",
    "   - 0: Nothing to note\n",
    "   - 1: ST-T Wave abnormality can range from mild symptoms to severe problems signals non-normal heart beat\n",
    "   - 2: Possible or definite left ventricular hypertrophy Enlarged heart's main pumping chamber\n",
    "8. thalach - maximum heart rate achieved\n",
    "9. exang - exercise induced angina (1 = yes; 0 = no)\n",
    "10. oldpeak - ST depression induced by exercise relative to rest looks at stress of heart during excercise unhealthy heart will stress more\n",
    "11. slope - the slope of the peak exercise ST segment\n",
    "    - 0: Upsloping: better heart rate with excercise (uncommon)\n",
    "    - 1: Flatsloping: minimal change (typical healthy heart)\n",
    "    - 2: Downslopins: signs of unhealthy heart\n",
    "12. ca - number of major vessels (0-3) colored by flourosopy\n",
    "    - colored vessel means the doctor can see the blood passing through\n",
    "    - the more blood movement the better (no clots)\n",
    "13. thal - thalium stress result\n",
    "    - 1,3: normal\n",
    "    - 6: fixed defect: used to be defect but ok now\n",
    "    - 7: reversable defect: no proper blood movement when excercising\n",
    "14. target - have disease or not (1=yes, 0=no) (= the predicted attribute)\n",
    "\n",
    "### Preparing the tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular EDA(exploratory data analysis) and plotting library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model from sklearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import RocCurveDisplay, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/heart.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "We can learn more about our dataset by visualizing the relationship between features and label.\n",
    "\n",
    "1. What kind of data do we have and how to treat different types?\n",
    "2. What is missing from the data and how to deal with it?\n",
    "3. Where are the outliers and why should we care about them?\n",
    "4. How can we add, change or remove features to get more out of our data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts().plot(\n",
    "    kind='bar',\n",
    "    color=[\"red\", \"lightblue\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there missing values?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heart Disease Frequency according to sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare target column with sex column\n",
    "pd.crosstab(df.target, df.sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.target, df.sex).plot(kind=\"bar\", color=[\"red\", \"blue\"])\n",
    "plt.title(\"Heart Disease Frequency for Sex\")\n",
    "plt.legend([\"Female\", \"Male\"])\n",
    "plt.xlabel(\"0 = No Disease, 1 = Disease\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel(\"Amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.plot(kind=\"hist\", bins=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and Max heart rate for heart disease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df.age[df.target == 1], df.thalach[df.target == 1], c='salmon')\n",
    "plt.scatter(df.age[df.target == 0], df.thalach[df.target == 0], c='lightblue')\n",
    "\n",
    "plt.title(\"Heart disease in function of Age and Max heart rate\")\n",
    "plt.legend([\"Disease\", \"No Disease\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart Disease Frequency per Chest Pain Type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.cp, df.target).plot.bar(color=[\"b\", 'r'])\n",
    "plt.title(\"Heart disease frequency per chest pain type\")\n",
    "plt.legend([\"No disease\", \"disease\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Chest pain type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10)) \n",
    "ax = sns.heatmap(corr_matrix, annot=True, cmap='YlGnBu', linewidths=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df.target\n",
    "X = df.drop([\"target\"], axis=1)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train 3 different models:\n",
    "1. LogisticRegression\n",
    "2. RandomForestClassifier\n",
    "3. KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"rdf\": RandomForestClassifier(),\n",
    "    \"lgr\": LogisticRegression(max_iter=100),\n",
    "    \"knn\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "def fit_and_score(models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"[Evaluate given machine learning models]\n",
    "\n",
    "    Args:\n",
    "        models ([List of scikitlearn model]): [Scikitlearn model]\n",
    "        X_train ([numpy array]): [Training feature]\n",
    "        y_train ([type]): [training label]\n",
    "        X_test ([type]): [testing features]\n",
    "        y_test ([type]): [testing label]\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    model_scores = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        model_scores[name] = model.score(X_test, y_test)\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "\n",
    "model_scores = fit_and_score(models, X_train, y_train, X_test, y_test)\n",
    "### Model comparison\n",
    "\n",
    "model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\n",
    "model_compare.T.plot.bar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n",
    "\n",
    "1. Hyperparameter turning\n",
    "2. Feature important\n",
    "3. Confusion matrix\n",
    "4. Cross-validation\n",
    "5. Precision\n",
    "6. Recall\n",
    "7. F1 score\n",
    "8. Classification Report\n",
    "9. ROC curve\n",
    "10. Area under the curve(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "knn = KNeighborsClassifier()\n",
    "for i in range(1,25):\n",
    "    knn.set_params(n_neighbors =i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    test_scores.append(knn.score(X_test, y_test))\n",
    "\n",
    "plt.plot(range(1,25),train_scores)\n",
    "plt.plot(range(1,25),test_scores)\n",
    "plt.xlabel(\"Number of neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train score', 'Test score'])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter turning with RandomizedSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regression_grid = {\"C\": np.logspace(-4, 4, 20), \"solver\": ['liblinear']}\n",
    "\n",
    "rf_grid = {\n",
    "    \"n_estimators\": np.arange(10, 100, 10),\n",
    "    \"max_depth\": [None, 3,  10],\n",
    "    \"min_samples_split\": np.arange(2, 20, 4),\n",
    "    \"min_samples_leaf\": np.arange(1, 20, 4)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "lr_searchCV = RandomizedSearchCV(LogisticRegression(),\n",
    "                                 log_regression_grid,\n",
    "                                 cv=5,\n",
    "                                 n_iter=20,\n",
    "                                 verbose=True)\n",
    "lr_searchCV.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_searchCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_searchCV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rfc_GSCV = GridSearchCV(RandomForestClassifier(), rf_grid, cv=5)\n",
    "\n",
    "rfc_GSCV.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_GSCV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate our machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr_searchCV.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC - ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(model, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Plot confusion_matrix using seaborn\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cbar=False)\n",
    "    plt.xlabel('True label')\n",
    "    plt.ylabel('Predicted')\n",
    "\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evalutaion matrix using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated accuracy\n",
    "\n",
    "cv_acc = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(cv_acc.mean())\n",
    "\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated precision\n",
    "\n",
    "cv_prec = cross_val_score(model, X, y, cv=5, scoring='precision')\n",
    "print(cv_prec.mean())\n",
    "\n",
    "\n",
    "# Cross-validated accuracy\n",
    "\n",
    "cv_recall = cross_val_score(model, X, y, cv=5, scoring='recall')\n",
    "print(cv_recall.mean())\n",
    "\n",
    "\n",
    "# Cross-validated accuracy\n",
    "\n",
    "cv_f1 = cross_val_score(model, X, y, cv=5, scoring='f1')\n",
    "print(cv_f1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "feature_dictionary = dict(zip(df.columns, model.coef_[0]))\n",
    "feature_dictionary\n",
    "feature_dictionary_dataframe = pd.DataFrame(feature_dictionary, index=['Coef'])\n",
    "feature_dictionary_dataframe.T.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.var()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "filter_model= SelectFromModel(model, max_features=12)\n",
    "filter_model.fit(X,y)\n",
    "X_filted = filter_model.transform(X)\n",
    "feature_names = np.array(X.columns)[filter_model.get_support()]\n",
    "X_filted_values = filter_model.transform(X)\n",
    "X_filted = pd.DataFrame(X_filted_values, columns =feature_names, index=None)\n",
    "X_filted\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filted,  y, test_size =0.2)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experimentation\n",
    "\n",
    "* Could we collect more data?\n",
    "* Could we try a better model?\n",
    "* Could you improve the current model?\n",
    "* If our model is good enough, how can we export it and share it with other people?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8476f40adbb31d316263111a5645b453d35d3e96db58041b0655f021c3b1406"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
